## diskANN:

### 综述

当前最先进的近似最近邻搜索 （ANNS） 算法生成的索引必须存储在主内存中，以便进行快速的高召回率搜索。这使得它们成本高昂，并限制了数据集的大小。在 64GB RAM 和廉价固态硬盘 （SSD） 的单个工作站上，算法从有着 10 亿个点的数据库中进行搜索。最后实现了高召回率、低查询延时以及高密度。

目标问题：\
有P个点，设计一个数据结构，对于q个询问以及一个目标点k，能快速得到q的前k个最近邻点集合G。(KNN)

问题转化：\
有P个点，设计一个数据结构，对于q个询问以及一个目标点k，最后返回的是一个关于k的邻域集合X。召回率的定义是$\frac{|X \bigcap G|}{k}$

KD树在维度超过20的时候通常会很慢；基于位置敏感哈希的方法 为索引大小和搜索时间之间的权衡提供了近乎最佳的保证，但它们未能利用点的分布，并且在真实数据集上被更新的基于图的方法所超越。在真实数据集上搜索时间与召回率方面的最佳算法通常是基于图形的算法，例如 HNSW 和 NSG。

倒排索引是一种常见的数据结构，用于快速查找相似对象。对于不同的聚类，寻找出最近的几个点的集合。这种方法内存占用很小，但是数据压缩可能有损失，导致最后的召回率低。

此外，还可以把数据集划分成不相交的分片，对于不同的分片构造内存的索引。这种方法内存占用高，但是召回率同样得到了提升。

Faiss 仅支持从 RAM 中搜索。因为即使使用 SSD，磁盘数据库的速度要慢几个数量级。而如果向量数据库要经过SSD进行查询，则需要减少对SSD的访存次数来进行优化。

DiskANN在十亿数量级的节点上，用64GB的RAM可以实现95%的召回率。同时延迟只有5ms。同时采用一种叫做Vamana的新算法，该算法在内存中也可以使用，使得搜索性能与HNSW/NSG相当。Vamana 可以与现成的向量压缩方案（如乘积量化）相结合来构建 DiskANN 系统。

### Vamana算法

贪心算法寻找最近邻：（算法1）

从p点出发，往它的出边一直寻找离$x_q$最近的点，直到找到k个最近邻点且搜索到的集合大小不改变。整个过程中,都要按照已经搜索的所有点到k点进行排序。（优先队列）

问题：如果p和最终的询问点$x_q$很远的话，会导致多次访问。

Robust Pruning Procedure: （算法2）

对于距离超过一定倍数（$\alpha$）的节点，直接剪枝跳过。到最后进行优化更新。只需要考虑p的最近节点即可。

Vamana：（一种把稠密图削减为稀疏图的方法）

- 1.找到离s最近的点（算法1）
- 2.找到离s最近的点和s的邻域（算法2）
- 3.如果当前邻域大小小于R，则把J更新成当前邻域+当前点；否则就通过算法2进行更新，使得最后出度只有R。

Vamasa与HNSW NSG的对比

最关键的是，HNSW 和 NSG 都没有可调参数 α，并且隐式使用 α = 1。这是让 Vamana 在图形度数和直径之间实现更好权衡的主要因素。Vamana 和 NSG 有添加长距离边，而 HNSW 通过仅向附近的点添加局部边。从随机图开始比从空图开始会产生更好的图形质量。

### DISKANN

提出问题：
在存储空间有限且访存很费时的基础上，如何构建出一个大量点的图，同时可以满足我们进行比较与查找。

一种方法是通过Kmeans等聚类技术将数据分区分为多个较小的分片，同时对每个分片进行单独索引。但是会增加搜索的延迟并且会降低吞吐量。

事实上，我们首先使用 k-means 将 10 亿个点数据集划分为 k 个集群（比如 k = 40），然后将每个基点分配给“最近的l个中心”（通常 l = 2 就足够了）。然后，我们为分配给每个集群的点构建 Vamana 索引（现在只有大约 N * l / k 个点，因此可以在内存中进行索引），最后通过简单的边并集将所有不同的图合并为一个图。（也就是说对于每个聚类，分别用l个索引进行代替）

我们将所有数据点的压缩向量存储在内存中，并将图形与全精度向量一起存储在 SSD 上。

DiskANN使用Beam Search进行搜索，参数W为前W个frequency的节点。如果W为1则是贪心搜索；W太大则可能浪费计算和SSD带宽。

todo DiskANN干了啥

全精度通常指的是使用32位（即单精度，Single Precision）浮点数来存储模型的权重和进行计算。半精度则是指使用16位（即半精度，Half Precision）浮点数来进行模型的权重存储和计算。

## FINGER：

观察出结论：
大多数距离计算对更好的搜索结果没有贡献。
也就是说，可以设置一个距离上界，当搜索的距离超过这个上界，则不参与计算。（剪枝）可以采用近似计算来减少计算量。

给定问题：

给出一个询问点$q$，以及一个中心点$c$。对于一个$c$的特定邻域点$d$，我们通过计算$q$和$d$的距离来更新查找的results。

采用L2距离。一个想法是可以把$c$进行正交分解。最后可以分解成一个正交和一个投影方向的向量。

由此可以得到：

$q = q_{proj} + q_{res},q_{proj} = \frac{c^Tq}{c^Tc}c,q_{res}=q-q_{proj}$

由此L2距离可以写成：

$|Dist|^2 = ||q - d||_2^2 = ||(q_{proj} - d_{proj})+(q_{res}-d_{res})||^2_2=||(q_{proj} - d_{proj})||^2_2 + ||(q_{res}-d_{res})||^2_2 = ||q_{proj}||^2_2 + ||d_{res}||^2_2 - 2q^T_{res}d_{res}$

$d_{proj}$和$d_{res}$在建图的时候就可以得到了；$||q-c||_2$在搜索算法运行的时候就已经被计算过了。因此可以通过一个计算得到$q^Tc$:

$q^Tc = \frac{||q|^2 + ||c||^2_2 - ||q-c||^2_2}{2}$

由此$q_{proj}$可以计算得到。唯一的未知项便是$q_{res}^Td_{res}$。需要设计一个近似量来模拟$cos(q_{res},d_{res})$。
